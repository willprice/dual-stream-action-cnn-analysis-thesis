<!DOCTYPE html>
<!-- saved from url=(0051)http://cs231n.github.io/neural-networks-case-study/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>CS231n Convolutional Neural Networks for Visual Recognition</title>
    <meta name="viewport" content="width=device-width">
    <meta name="description" content="Course materials and notes for Stanford class CS231n: Convolutional Neural Networks for Visual Recognition.">
    <link rel="canonical" href="http://cs231n.github.io/neural-networks-case-study/">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="./1-8-case-study_files/main.css">

    <!-- Google fonts -->
    <link href="./1-8-case-study_files/css" rel="stylesheet" type="text/css">

    <!-- Google tracking -->
    <script async="" src="http://www.google-analytics.com/analytics.js"></script><script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-46895817-2', 'auto');
      ga('send', 'pageview');

    </script>
    
<style>#cVim-command-bar, #cVim-command-bar-mode, #cVim-command-bar-input, #cVim-command-bar-search-results,
.cVim-completion-item, .cVim-completion-item .cVim-full, .cVim-completion-item .cVim-left,
.cVim-completion-item .cVim-right {
  font-family: Helvetica, Helvetica Neue, Neue, sans-serif, monospace, Arial;
  font-size: 10pt !important;
  -webkit-font-smoothing: antialiased !important;
}

#cVim-command-bar {
  position: fixed;
  z-index: 2147483646;
  background-color: #1b1d1e;
  color: #bbb;
  display: none;
  box-sizing: content-box;
  box-shadow: 0 3px 3px rgba(0,0,0,0.4);
  left: 0;
  width: 100%;
  height: 20px;
}

#cVim-command-bar-mode {
  display: inline-block;
  vertical-align: middle;
  box-sizing: border-box;
  padding-left: 2px;
  height: 100%;
  width: 10px;
  padding-top: 2px;
  color: #888;
}

#cVim-command-bar-input {
  background-color: #1b1d1e;
  color: #bbb;
  height: 100%;
  right: 0;
  top: 0;
  width: calc(100% - 10px);
  position: absolute;
}

#cVim-command-bar-search-results {
  position: fixed;
  width: 100%;
  overflow: hidden;
  z-index: 2147483647;
  left: 0;
  box-shadow: 0 3px 3px rgba(0,0,0,0.4);
  background-color: #1c1c1c;
}

.cVim-completion-item, .cVim-completion-item .cVim-full, .cVim-completion-item .cVim-left, .cVim-completion-item .cVim-right {
  text-overflow: ellipsis;
  padding: 1px;
  display: inline-block;
  box-sizing: border-box;
  vertical-align: middle;
  overflow: hidden;
  white-space: nowrap;
}

.cVim-completion-item:nth-child(even) {
  background-color: #1f1f1f;
}

.cVim-completion-item {
  width: 100%; left: 0;
  color: #bcbcbc;
}

.cVim-completion-item[active] {
  width: 100%; left: 0;
  color: #1b1d1e;
  background-color: #f1f1f1;
}

.cVim-completion-item[active] span {
  color: #1b1d1e;
}

.cVim-completion-item .cVim-left {
  color: #fff;
  width: 37%;
}

.cVim-completion-item .cVim-right {
  font-style: italic;
  color: #888;
  width: 57%;
}


#cVim-link-container, .cVim-link-hint,
#cVim-hud, #cVim-status-bar {
  font-family: Helvetica, Helvetica Neue, Neue, sans-serif, monospace, Arial;
  font-size: 10pt !important;
  -webkit-font-smoothing: antialiased !important;
}

#cVim-link-container {
  position: absolute;
  pointer-events: none;
  width: 100%; left: 0;
  height: 100%; top: 0;
  z-index: 2147483647;
}

.cVim-link-hint {
  position: absolute;
  color: #302505 !important;
  background-color: #ffd76e !important;
  border-radius: 2px !important;
  padding: 2px !important;
  font-size: 8pt !important;
  font-weight: 500 !important;
  text-transform: uppercase !important;
  border: 1px solid #ad810c;
  display: inline-block !important;
  vertical-align: middle !important;
  text-align: center !important;
  box-shadow: 2px 2px 1px rgba(0,0,0,0.25) !important;
}

.cVim-link-hint_match {
  color: #777;
  text-transform: uppercase !important;
}


#cVim-hud {
  background-color: rgba(28,28,28,0.9);
  position: fixed !important;
  transition: right 0.2s ease-out;
  z-index: 24724289;
}

#cVim-hud span {
  padding: 2px;
  padding-left: 4px;
  padding-right: 4px;
  color: #8f8f8f;
  font-size: 10pt;
}

#cVim-frames-outline {
  position: fixed;
  width: 100%;
  height: 100%;
  left: 0;
  top: 0;
  right: 0;
  z-index: 9999999999;
  box-sizing: border-box;
  border: 3px solid yellow;
}
</style><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax_LineBox {display: table!important}
.MathJax_LineBox span {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Main; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Main-bold; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Main-italic; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Math-italic; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Caligraphic; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Size1; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Size2; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Size3; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf?V=2.7.0') format('opentype')}
@font-face {font-family: MathJax_Size4; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf?V=2.7.0') format('opentype')}
.MathJax .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">@font-face {font-family: MathJax_AMS; src: url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff?V=2.7.0') format('woff'), url('http://cdn.mathjax.org/mathjax/2.7-latest/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf?V=2.7.0') format('opentype')}
</style></head>


    <body style=""><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>

    <header class="site-header">

  <div class="wrap title-wrap">
    <a class="site-title" href="http://cs231n.github.io/">CS231n Convolutional Neural Networks for Visual Recognition</a>
  </div>

</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">

  <header class="post-header">
    <h1></h1>
  </header>

  <article class="post-content">
  <p>Table of Contents:</p>

<ul>
  <li><a href="http://cs231n.github.io/neural-networks-case-study/#data">Generating some data</a></li>
  <li><a href="http://cs231n.github.io/neural-networks-case-study/#linear">Training a Softmax Linear Classifier</a>
    <ul>
      <li><a href="http://cs231n.github.io/neural-networks-case-study/#init">Initialize the parameters</a></li>
      <li><a href="http://cs231n.github.io/neural-networks-case-study/#scores">Compute the class scores</a></li>
      <li><a href="http://cs231n.github.io/neural-networks-case-study/#loss">Compute the loss</a></li>
      <li><a href="http://cs231n.github.io/neural-networks-case-study/#grad">Computing the analytic gradient with backpropagation</a></li>
      <li><a href="http://cs231n.github.io/neural-networks-case-study/#update">Performing a parameter update</a></li>
      <li><a href="http://cs231n.github.io/neural-networks-case-study/#together">Putting it all together: Training a Softmax Classifier</a></li>
    </ul>
  </li>
  <li><a href="http://cs231n.github.io/neural-networks-case-study/#net">Training a Neural Network</a></li>
  <li><a href="http://cs231n.github.io/neural-networks-case-study/#summary">Summary</a></li>
</ul>

<p>In this section we’ll walk through a complete implementation of a toy Neural Network in 2 dimensions. We’ll first implement a simple linear classifier and then extend the code to a 2-layer Neural Network. As we’ll see, this extension is surprisingly simple and very few changes are necessary.</p>

<p><a name="data"></a></p>

<h2 id="generating-some-data">Generating some data</h2>

<p>Lets generate a classification dataset that is not easily linearly separable. Our favorite example is the spiral dataset, which can be generated as follows:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">N</span> <span class="o">=</span> <span class="mi">100</span> <span class="c"># number of points per class</span>
<span class="n">D</span> <span class="o">=</span> <span class="mi">2</span> <span class="c"># dimensionality</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">3</span> <span class="c"># number of classes</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="o">*</span><span class="n">K</span><span class="p">,</span><span class="n">D</span><span class="p">))</span> <span class="c"># data matrix (each row = single example)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="n">K</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'uint8'</span><span class="p">)</span> <span class="c"># class labels</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
  <span class="n">ix</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="n">j</span><span class="p">,</span><span class="n">N</span><span class="o">*</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
  <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span><span class="p">)</span> <span class="c"># radius</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">j</span><span class="o">*</span><span class="mi">4</span><span class="p">,(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span><span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">*</span><span class="mf">0.2</span> <span class="c"># theta</span>
  <span class="n">X</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">r</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">r</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">t</span><span class="p">)]</span>
  <span class="n">y</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="n">j</span>
<span class="c"># lets visualize the data:</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Spectral</span><span class="p">)</span>
</code></pre>
</div>

<div class="fig figcenter fighighlight">
  <img src="./1-8-case-study_files/spiral_raw.png">
  <div class="figcaption">
    The toy spiral data consists of three classes (blue, red, yellow) that are not linearly separable.
  </div>
</div>

<p>Normally we would want to preprocess the dataset so that each feature has zero mean and unit standard deviation, but in this case the features are already in a nice range from -1 to 1, so we skip this step.</p>

<p><a name="linear"></a></p>

<h2 id="training-a-softmax-linear-classifier">Training a Softmax Linear Classifier</h2>

<p><a name="init"></a></p>

<h3 id="initialize-the-parameters">Initialize the parameters</h3>

<p>Lets first train a Softmax classifier on this classification dataset. As we saw in the previous sections, the Softmax classifier has a linear score function and uses the cross-entropy loss. The parameters of the linear classifier consist of a weight matrix <code class="highlighter-rouge">W</code> and a bias vector <code class="highlighter-rouge">b</code> for each class. Lets first initialize these parameters to be random numbers:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># initialize parameters randomly</span>
<span class="n">W</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">D</span><span class="p">,</span><span class="n">K</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">K</span><span class="p">))</span>
</code></pre>
</div>

<p>Recall that we <code class="highlighter-rouge">D = 2</code> is the dimensionality and <code class="highlighter-rouge">K = 3</code> is the number of classes.</p>

<p><a name="scores"></a></p>

<h3 id="compute-the-class-scores">Compute the class scores</h3>

<p>Since this is a linear classifier, we can compute all class scores very simply in parallel with a single matrix multiplication:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># compute class scores for a linear classifier</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
</code></pre>
</div>

<p>In this example we have 300 2-D points, so after this multiplication the array <code class="highlighter-rouge">scores</code> will have size [300 x 3], where each row gives the class scores corresponding to the 3 classes (blue, red, yellow).</p>

<p><a name="loss"></a></p>

<h3 id="compute-the-loss">Compute the loss</h3>

<p>The second key ingredient we need is a loss function, which is a differentiable objective that quantifies our unhappiness with the computed class scores. Intuitively, we want the correct class to have a higher score than the other classes. When this is the case, the loss should be low and otherwise the loss should be high. There are many ways to quantify this intuition, but in this example lets use the cross-entropy loss that is associated with the Softmax classifier. Recall that if <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1" style="width: 0.72em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.566em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.335em 1000.57em 2.564em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3" style="font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></span></span><script type="math/tex" id="MathJax-Element-1">f</script> is the array of class scores for a single example (e.g. array of 3 numbers here), then the Softmax classifier computes the loss for that example as:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/munder&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-4" style="width: 11.119em; display: inline-block;"><span style="display: inline-block; position: relative; width: 9.121em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(2.154em 1008.87em 5.484em -999.997em); top: -4.045em; left: 0em;"><span class="mrow" id="MathJax-Span-5"><span class="msubsup" id="MathJax-Span-6"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px;"><span style="position: absolute; clip: rect(3.179em 1000.67em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-7" style="font-family: MathJax_Math-italic;">L</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.669em;"><span class="mi" id="MathJax-Span-8" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="mo" id="MathJax-Span-9" style="font-family: MathJax_Main; padding-left: 0.259em;">=</span><span class="mo" id="MathJax-Span-10" style="font-family: MathJax_Main; padding-left: 0.259em;">−</span><span class="mi" id="MathJax-Span-11" style="font-family: MathJax_Main; padding-left: 0.156em;">log</span><span class="mo" id="MathJax-Span-12"></span><span class="mrow" id="MathJax-Span-13"><span class="mo" id="MathJax-Span-14" style="vertical-align: 0em;"><span style="font-family: MathJax_Size4;">(</span></span><span class="mfrac" id="MathJax-Span-15"><span style="display: inline-block; position: relative; width: 2.871em; height: 0px; margin-right: 0.105em; margin-left: 0.105em;"><span style="position: absolute; clip: rect(2.923em 1001.39em 4.152em -999.997em); top: -4.659em; left: 50%; margin-left: -0.715em;"><span class="msubsup" id="MathJax-Span-16"><span style="display: inline-block; position: relative; width: 1.386em; height: 0px;"><span style="position: absolute; clip: rect(3.384em 1000.41em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-17" style="font-family: MathJax_Math-italic;">e</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -4.454em; left: 0.464em;"><span class="texatom" id="MathJax-Span-18"><span class="mrow" id="MathJax-Span-19"><span class="msubsup" id="MathJax-Span-20"><span style="display: inline-block; position: relative; width: 0.873em; height: 0px;"><span style="position: absolute; clip: rect(3.332em 1000.41em 4.306em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-21" style="font-size: 70.7%; font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.361em;"><span class="texatom" id="MathJax-Span-22"><span class="mrow" id="MathJax-Span-23"><span class="msubsup" id="MathJax-Span-24"><span style="display: inline-block; position: relative; width: 0.464em; height: 0px;"><span style="position: absolute; clip: rect(3.64em 1000.26em 4.255em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-25" style="font-size: 50%; font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.259em;"><span class="mi" id="MathJax-Span-26" style="font-size: 50%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(2.974em 1002.72em 4.562em -999.997em); top: -3.122em; left: 50%; margin-left: -1.381em;"><span class="mrow" id="MathJax-Span-27"><span class="munderover" id="MathJax-Span-28"><span style="display: inline-block; position: relative; width: 1.437em; height: 0px;"><span style="position: absolute; clip: rect(3.076em 1001.03em 4.408em -999.997em); top: -3.993em; left: 0em;"><span class="mo" id="MathJax-Span-29" style="font-family: MathJax_Size1; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.686em; left: 1.078em;"><span class="mi" id="MathJax-Span-30" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-31" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 1.13em; height: 0px;"><span style="position: absolute; clip: rect(3.384em 1000.41em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-32" style="font-family: MathJax_Math-italic;">e</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -4.352em; left: 0.464em;"><span class="texatom" id="MathJax-Span-33"><span class="mrow" id="MathJax-Span-34"><span class="msubsup" id="MathJax-Span-35"><span style="display: inline-block; position: relative; width: 0.617em; height: 0px;"><span style="position: absolute; clip: rect(3.332em 1000.41em 4.306em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-36" style="font-size: 70.7%; font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.361em;"><span class="mi" id="MathJax-Span-37" style="font-size: 50%; font-family: MathJax_Math-italic;">j</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(0.873em 1002.87em 1.232em -999.997em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.871em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.078em;"></span></span></span></span><span class="mo" id="MathJax-Span-38" style="vertical-align: 0em;"><span style="font-family: MathJax_Size4;">)</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.05em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.622em; border-left: 0px solid; width: 0px; height: 3.816em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>L</mi><mi>i</mi></msub><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mrow><mo>(</mo><mfrac><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><msub><mi>f</mi><mrow class="MJX-TeXAtom-ORD"><msub><mi>y</mi><mi>i</mi></msub></mrow></msub></mrow></msup><mrow><munder><mo>∑</mo><mi>j</mi></munder><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><msub><mi>f</mi><mi>j</mi></msub></mrow></msup></mrow></mfrac><mo>)</mo></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-2">L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right)</script>

<p>We can see that the Softmax classifier interprets every element of <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-39" style="width: 0.72em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.566em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.335em 1000.57em 2.564em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-40"><span class="mi" id="MathJax-Span-41" style="font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></span></span><script type="math/tex" id="MathJax-Element-3">f</script> as holding the (unnormalized) log probabilities of the three classes. We exponentiate these to get (unnormalized) probabilities, and then normalize them to get probabilites. Therefore, the expression inside the log is the normalized probability of the correct class. Note how this expression works: this quantity is always between 0 and 1. When the probability of the correct class is very small (near 0), the loss will go towards (postiive) infinity. Conversely, when the correct class probability goes towards 1, the loss will go towards zero because <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-42" style="width: 5.228em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.255em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.283em 1004.2em 2.615em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-43"><span class="mi" id="MathJax-Span-44" style="font-family: MathJax_Math-italic;">l</span><span class="mi" id="MathJax-Span-45" style="font-family: MathJax_Math-italic;">o</span><span class="mi" id="MathJax-Span-46" style="font-family: MathJax_Math-italic;">g<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-47" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-48" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-49" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-50" style="font-family: MathJax_Main; padding-left: 0.259em;">=</span><span class="mn" id="MathJax-Span-51" style="font-family: MathJax_Main; padding-left: 0.259em;">0</span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.378em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></math></span></span><script type="math/tex" id="MathJax-Element-4">log(1) = 0</script>. Hence, the expression for <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-52" style="width: 1.283em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.386em 1001.03em 2.513em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-53"><span class="msubsup" id="MathJax-Span-54"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px;"><span style="position: absolute; clip: rect(3.179em 1000.67em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-55" style="font-family: MathJax_Math-italic;">L</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.669em;"><span class="mi" id="MathJax-Span-56" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-5">L_i</script> is low when the correct class probability is high, and it’s very high when it is low.</p>

<p>Recall also that the full Softmax classifier loss is then defined as the average cross-entropy loss over the training examples and the regularization:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display"><span class="MathJax MathJax_FullWidth" id="MathJax-Element-6-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mrow class=&quot;MJX-TeXAtom-OP MJX-fixedlimits&quot;&gt;&lt;munder&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mfrac&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/munder&gt;&lt;msub&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x23DF;&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;mtext&gt;data loss&lt;/mtext&gt;&lt;/munder&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;munder&gt;&lt;mrow class=&quot;MJX-TeXAtom-OP MJX-fixedlimits&quot;&gt;&lt;munder&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/munder&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;/munder&gt;&lt;msubsup&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msubsup&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x23DF;&lt;/mo&gt;&lt;/munder&gt;&lt;/mrow&gt;&lt;mtext&gt;regularization loss&lt;/mtext&gt;&lt;/munder&gt;&lt;mspace linebreak=&quot;newline&quot; /&gt;&lt;mspace linebreak=&quot;newline&quot; /&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-57" style="width: 100%; display: inline-block; min-width: 16.908em;"><span style="display: inline-block; position: relative; width: 100%; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(4.152em 1013.84em 9.07em -999.997em); top: -5.633em; left: 0em; width: 100%;"><span class="mrow" id="MathJax-Span-58"><span style="display: inline-block; position: relative; width: 100%; height: 0px;"><span style="position: absolute; clip: rect(3.691em 1013.84em 8.199em -999.997em); top: -5.172em; left: 50%; margin-left: -6.913em;"><span class="mi" id="MathJax-Span-59" style="font-family: MathJax_Math-italic;">L</span><span class="mo" id="MathJax-Span-60" style="font-family: MathJax_Main; padding-left: 0.259em;">=</span><span class="munderover" id="MathJax-Span-61" style="padding-left: 0.259em;"><span style="display: inline-block; position: relative; width: 4.05em; height: 0px;"><span style="position: absolute; clip: rect(2.769em 1004.05em 6.304em -999.997em); top: -4.249em; left: 0em;"><span class="texatom" id="MathJax-Span-62"><span class="mrow" id="MathJax-Span-63"><span class="munderover" id="MathJax-Span-64"><span style="display: inline-block; position: relative; width: 4.05em; height: 0px;"><span style="position: absolute; clip: rect(2.513em 1004em 5.33em -999.997em); top: -3.993em; left: 0.003em;"><span class="mrow" id="MathJax-Span-65"><span class="mfrac" id="MathJax-Span-66"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px; margin-right: 0.105em; margin-left: 0.105em;"><span style="position: absolute; clip: rect(3.179em 1000.41em 4.152em -999.997em); top: -4.659em; left: 50%; margin-left: -0.254em;"><span class="mn" id="MathJax-Span-67" style="font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.179em 1000.87em 4.152em -999.997em); top: -3.327em; left: 50%; margin-left: -0.459em;"><span class="mi" id="MathJax-Span-68" style="font-family: MathJax_Math-italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.105em;"></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(0.873em 1001.03em 1.232em -999.997em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.027em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.078em;"></span></span></span></span><span class="munderover" id="MathJax-Span-69" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 1.437em; height: 0px;"><span style="position: absolute; clip: rect(2.871em 1001.39em 4.613em -999.997em); top: -3.993em; left: 0em;"><span class="mo" id="MathJax-Span-70" style="font-family: MathJax_Size2; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.384em 1000.21em 4.255em -999.997em); top: -2.918em; left: 0.617em;"><span class="mi" id="MathJax-Span-71" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-72" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px;"><span style="position: absolute; clip: rect(3.179em 1000.67em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-73" style="font-family: MathJax_Math-italic;">L</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.669em;"><span class="mi" id="MathJax-Span-74" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(1.693em 1004.05em 2.564em -999.997em); top: -0.51em; left: 0em;"><span class="mo" id="MathJax-Span-75" style=""><span style="display: inline-block; position: relative; width: 4.05em; height: 0px;"><span style="position: absolute; font-family: MathJax_Size4; top: -3.993em; left: 0.003em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; font-family: MathJax_Size4; top: -3.993em; left: 3.537em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; font-family: MathJax_Size4; top: -3.993em; left: 1.539em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 0.412em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 0.822em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 1.181em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 2.41em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 2.82em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 3.179em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.255em;"></span></span><span style="position: absolute; clip: rect(3.332em 1002.62em 4.255em -999.997em); top: -1.432em; left: 0.669em;"><span class="mtext" id="MathJax-Span-76" style="font-size: 70.7%; font-family: MathJax_Main;">data loss</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="mo" id="MathJax-Span-77" style="font-family: MathJax_Main; padding-left: 0.207em;">+</span><span class="munderover" id="MathJax-Span-78" style="padding-left: 0.207em;"><span style="display: inline-block; position: relative; width: 6.611em; height: 0px;"><span style="position: absolute; clip: rect(2.82em 1006.61em 6.406em -999.997em); top: -4.301em; left: 0em;"><span class="texatom" id="MathJax-Span-79"><span class="mrow" id="MathJax-Span-80"><span class="munderover" id="MathJax-Span-81"><span style="display: inline-block; position: relative; width: 6.611em; height: 0px;"><span style="position: absolute; clip: rect(2.513em 1006.61em 5.382em -999.997em); top: -3.993em; left: 0.003em;"><span class="mrow" id="MathJax-Span-82"><span class="mfrac" id="MathJax-Span-83"><span style="display: inline-block; position: relative; width: 0.617em; height: 0px; margin-right: 0.105em; margin-left: 0.105em;"><span style="position: absolute; clip: rect(3.179em 1000.41em 4.152em -999.997em); top: -4.659em; left: 50%; margin-left: -0.254em;"><span class="mn" id="MathJax-Span-84" style="font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.179em 1000.46em 4.152em -999.997em); top: -3.327em; left: 50%; margin-left: -0.254em;"><span class="mn" id="MathJax-Span-85" style="font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(0.873em 1000.62em 1.232em -999.997em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.617em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.078em;"></span></span></span></span><span class="mi" id="MathJax-Span-86" style="font-family: MathJax_Math-italic;">λ</span><span class="munderover" id="MathJax-Span-87" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 1.437em; height: 0px;"><span style="position: absolute; clip: rect(2.871em 1001.39em 4.613em -999.997em); top: -3.993em; left: 0em;"><span class="mo" id="MathJax-Span-88" style="font-family: MathJax_Size2; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.332em 1000.36em 4.255em -999.997em); top: -2.866em; left: 0.515em;"><span class="mi" id="MathJax-Span-89" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="munderover" id="MathJax-Span-90" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 1.437em; height: 0px;"><span style="position: absolute; clip: rect(2.871em 1001.39em 4.613em -999.997em); top: -3.993em; left: 0em;"><span class="mo" id="MathJax-Span-91" style="font-family: MathJax_Size2; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.332em 1000.21em 4.255em -999.997em); top: -2.866em; left: 0.617em;"><span class="mi" id="MathJax-Span-92" style="font-size: 70.7%; font-family: MathJax_Math-italic;">l</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-93" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 1.796em; height: 0px;"><span style="position: absolute; clip: rect(3.179em 1001.03em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-94" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.105em;"></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.384em 1000.41em 4.152em -999.997em); top: -4.352em; left: 1.13em;"><span class="mn" id="MathJax-Span-95" style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.332em 1000.87em 4.306em -999.997em); top: -3.686em; left: 0.925em;"><span class="texatom" id="MathJax-Span-96"><span class="mrow" id="MathJax-Span-97"><span class="mi" id="MathJax-Span-98" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span class="mo" id="MathJax-Span-99" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-100" style="font-size: 70.7%; font-family: MathJax_Math-italic;">l</span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(1.693em 1006.61em 2.564em -999.997em); top: -0.459em; left: 0em;"><span class="mo" id="MathJax-Span-101" style=""><span style="display: inline-block; position: relative; width: 6.611em; height: 0px;"><span style="position: absolute; font-family: MathJax_Size4; top: -3.993em; left: 0.003em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; font-family: MathJax_Size4; top: -3.993em; left: 6.15em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; font-family: MathJax_Size4; top: -3.993em; left: 2.871em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 0.412em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 0.771em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 1.13em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 1.437em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 1.796em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 2.154em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 2.513em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 3.691em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 4.05em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 4.408em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 4.767em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 5.074em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 5.433em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -3.993em; left: 5.791em;"><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.306em;"></span></span><span style="position: absolute; clip: rect(3.332em 1005.48em 4.408em -999.997em); top: -1.381em; left: 0.566em;"><span class="mtext" id="MathJax-Span-102" style="font-size: 70.7%; font-family: MathJax_Main;">regularization loss</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 5.177em;"></span></span><span style="position: absolute; clip: rect(3.845em 1000em 4.152em -999.997em); top: -0.715em; left: 50%; margin-left: 0em;"><span class="mspace" id="MathJax-Span-103" style="height: 0em; vertical-align: 0em; width: 0em; display: inline-block; overflow: hidden;"></span><span class="mspace" id="MathJax-Span-104" style="height: 0em; vertical-align: 0em; width: 0em; display: inline-block; overflow: hidden;"></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 5.638em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -4.059em; border-left: 0px solid; width: 0px; height: 5.753em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>L</mi><mo>=</mo><munder><mrow class="MJX-TeXAtom-OP MJX-fixedlimits"><munder><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><munder><mo>∑</mo><mi>i</mi></munder><msub><mi>L</mi><mi>i</mi></msub></mrow><mo>⏟</mo></munder></mrow><mtext>data loss</mtext></munder><mo>+</mo><munder><mrow class="MJX-TeXAtom-OP MJX-fixedlimits"><munder><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>λ</mi><munder><mo>∑</mo><mi>k</mi></munder><munder><mo>∑</mo><mi>l</mi></munder><msubsup><mi>W</mi><mrow class="MJX-TeXAtom-ORD"><mi>k</mi><mo>,</mo><mi>l</mi></mrow><mn>2</mn></msubsup></mrow><mo>⏟</mo></munder></mrow><mtext>regularization loss</mtext></munder><mspace linebreak="newline"></mspace><mspace linebreak="newline"></mspace></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-6">L =  \underbrace{ \frac{1}{N} \sum_i L_i }_\text{data loss} + \underbrace{ \frac{1}{2} \lambda \sum_k\sum_l W_{k,l}^2 }_\text{regularization loss} \\\\</script>

<p>Given the array of <code class="highlighter-rouge">scores</code> we’ve computed above, we can compute the loss. First, the way to obtain the probabilities is straight forward:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># get unnormalized probabilities</span>
<span class="n">exp_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="c"># normalize them for each example</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">exp_scores</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">exp_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre>
</div>

<p>We now have an array <code class="highlighter-rouge">probs</code> of size [300 x 3], where each row now contains the class probabilities. In particular, since we’ve normalized them every row now sums to one. We can now query for the  log probabilities assigned to the correct classes in each example:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">corect_logprobs</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">),</span><span class="n">y</span><span class="p">])</span>
</code></pre>
</div>

<p>The array <code class="highlighter-rouge">correct_logprobs</code> is a 1D array of just the probabilities assigned to the correct classes for each example. The full loss is then the average of these log probabilities and the regularization loss:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># compute the loss: average cross-entropy loss and regularization</span>
<span class="n">data_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">corect_logprobs</span><span class="p">)</span><span class="o">/</span><span class="n">num_examples</span>
<span class="n">reg_loss</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">reg</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">W</span><span class="o">*</span><span class="n">W</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">data_loss</span> <span class="o">+</span> <span class="n">reg_loss</span>
</code></pre>
</div>

<p>In this code, the regularization strength <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-7-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-105" style="width: 0.72em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.566em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.335em 1000.51em 2.359em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-106"><span class="mi" id="MathJax-Span-107" style="font-family: MathJax_Math-italic;">λ</span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>λ</mi></math></span></span><script type="math/tex" id="MathJax-Element-7">\lambda</script> is stored inside the <code class="highlighter-rouge">reg</code>. The convenience factor of <code class="highlighter-rouge">0.5</code> multiplying the regularization will become clear in a second. Evaluating this in the beginning (with random parameters) might give us <code class="highlighter-rouge">loss = 1.1</code>, which is <code class="highlighter-rouge">np.log(1.0/3)</code>, since with small initial random weights all probabilities assigned to all classes are about one third. We now want to make the loss as low as possible, with <code class="highlighter-rouge">loss = 0</code> as the absolute lower bound. But the lower the loss is, the higher are the probabilities assigned to the correct classes for all examples.</p>

<p><a name="grad"></a></p>

<h3 id="computing-the-analytic-gradient-with-backpropagation">Computing the Analytic Gradient with Backpropagation</h3>

<p>We have a way of evaluating the loss, and now we have to minimize it. We’ll do so with gradient descent. That is, we start with random parameters (as shown above), and evaluate the gradient of the loss function with respect to the parameters, so that we know how we should change the parameters to decrease the loss. Lets introduce the intermediate variable <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-8-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-108" style="width: 0.669em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.515em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.591em 1000.51em 2.564em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-109"><span class="mi" id="MathJax-Span-110" style="font-family: MathJax_Math-italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-8">p</script>, which is a vector of the (normalized) probabilities. The loss for one example is:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-9-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mrow&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/munder&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mspace width=&quot;1in&quot; /&gt;&lt;msub&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-111" style="width: 20.392em; display: inline-block;"><span style="display: inline-block; position: relative; width: 16.703em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(0.617em 1016.55em 3.742em -999.997em); top: -2.303em; left: 0em;"><span class="mrow" id="MathJax-Span-112"><span class="msubsup" id="MathJax-Span-113"><span style="display: inline-block; position: relative; width: 0.925em; height: 0px;"><span style="position: absolute; clip: rect(3.384em 1000.51em 4.357em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-114" style="font-family: MathJax_Math-italic;">p</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.515em;"><span class="mi" id="MathJax-Span-115" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="mo" id="MathJax-Span-116" style="font-family: MathJax_Main; padding-left: 0.259em;">=</span><span class="mfrac" id="MathJax-Span-117" style="padding-left: 0.259em;"><span style="display: inline-block; position: relative; width: 2.871em; height: 0px; margin-right: 0.105em; margin-left: 0.105em;"><span style="position: absolute; clip: rect(2.974em 1001.18em 4.152em -999.997em); top: -4.659em; left: 50%; margin-left: -0.612em;"><span class="msubsup" id="MathJax-Span-118"><span style="display: inline-block; position: relative; width: 1.181em; height: 0px;"><span style="position: absolute; clip: rect(3.384em 1000.41em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-119" style="font-family: MathJax_Math-italic;">e</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -4.352em; left: 0.464em;"><span class="texatom" id="MathJax-Span-120"><span class="mrow" id="MathJax-Span-121"><span class="msubsup" id="MathJax-Span-122"><span style="display: inline-block; position: relative; width: 0.669em; height: 0px;"><span style="position: absolute; clip: rect(3.332em 1000.41em 4.306em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-123" style="font-size: 70.7%; font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.361em;"><span class="mi" id="MathJax-Span-124" style="font-size: 50%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(2.974em 1002.72em 4.562em -999.997em); top: -3.122em; left: 50%; margin-left: -1.381em;"><span class="mrow" id="MathJax-Span-125"><span class="munderover" id="MathJax-Span-126"><span style="display: inline-block; position: relative; width: 1.437em; height: 0px;"><span style="position: absolute; clip: rect(3.076em 1001.03em 4.408em -999.997em); top: -3.993em; left: 0em;"><span class="mo" id="MathJax-Span-127" style="font-family: MathJax_Size1; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.686em; left: 1.078em;"><span class="mi" id="MathJax-Span-128" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-129" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 1.13em; height: 0px;"><span style="position: absolute; clip: rect(3.384em 1000.41em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-130" style="font-family: MathJax_Math-italic;">e</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -4.352em; left: 0.464em;"><span class="texatom" id="MathJax-Span-131"><span class="mrow" id="MathJax-Span-132"><span class="msubsup" id="MathJax-Span-133"><span style="display: inline-block; position: relative; width: 0.617em; height: 0px;"><span style="position: absolute; clip: rect(3.332em 1000.41em 4.306em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-134" style="font-size: 70.7%; font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.361em;"><span class="mi" id="MathJax-Span-135" style="font-size: 50%; font-family: MathJax_Math-italic;">j</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(0.873em 1002.87em 1.232em -999.997em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.871em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.078em;"></span></span></span></span><span class="mspace" id="MathJax-Span-136" style="height: 0em; vertical-align: 0em; width: 4.921em; display: inline-block; overflow: hidden;"></span><span class="msubsup" id="MathJax-Span-137"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px;"><span style="position: absolute; clip: rect(3.179em 1000.67em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-138" style="font-family: MathJax_Math-italic;">L</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.669em;"><span class="mi" id="MathJax-Span-139" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="mo" id="MathJax-Span-140" style="font-family: MathJax_Main; padding-left: 0.259em;">=</span><span class="mo" id="MathJax-Span-141" style="font-family: MathJax_Main; padding-left: 0.259em;">−</span><span class="mi" id="MathJax-Span-142" style="font-family: MathJax_Main; padding-left: 0.156em;">log</span><span class="mo" id="MathJax-Span-143"></span><span class="mrow" id="MathJax-Span-144"><span class="mo" id="MathJax-Span-145" style="vertical-align: 0em;"><span style="font-family: MathJax_Size1;">(</span></span><span class="msubsup" id="MathJax-Span-146"><span style="display: inline-block; position: relative; width: 1.13em; height: 0px;"><span style="position: absolute; clip: rect(3.384em 1000.51em 4.357em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-147" style="font-family: MathJax_Math-italic;">p</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.515em;"><span class="texatom" id="MathJax-Span-148"><span class="mrow" id="MathJax-Span-149"><span class="msubsup" id="MathJax-Span-150"><span style="display: inline-block; position: relative; width: 0.566em; height: 0px;"><span style="position: absolute; clip: rect(3.537em 1000.36em 4.306em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-151" style="font-size: 70.7%; font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.361em;"><span class="mi" id="MathJax-Span-152" style="font-size: 50%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="mo" id="MathJax-Span-153" style="vertical-align: 0em;"><span style="font-family: MathJax_Size1;">)</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.308em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.622em; border-left: 0px solid; width: 0px; height: 3.566em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>p</mi><mi>k</mi></msub><mo>=</mo><mfrac><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><msub><mi>f</mi><mi>k</mi></msub></mrow></msup><mrow><munder><mo>∑</mo><mi>j</mi></munder><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><msub><mi>f</mi><mi>j</mi></msub></mrow></msup></mrow></mfrac><mspace width="1in"></mspace><msub><mi>L</mi><mi>i</mi></msub><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mrow><mo>(</mo><msub><mi>p</mi><mrow class="MJX-TeXAtom-ORD"><msub><mi>y</mi><mi>i</mi></msub></mrow></msub><mo>)</mo></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-9">p_k = \frac{e^{f_k}}{ \sum_j e^{f_j} } \hspace{1in} L_i =-\log\left(p_{y_i}\right)</script>

<p>We now wish to understand how the computed scores inside <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-10-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-154" style="width: 0.72em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.566em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.335em 1000.57em 2.564em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-155"><span class="mi" id="MathJax-Span-156" style="font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></span></span><script type="math/tex" id="MathJax-Element-10">f</script> should change to decrease the loss <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-11-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-157" style="width: 1.283em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.386em 1001.03em 2.513em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-158"><span class="msubsup" id="MathJax-Span-159"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px;"><span style="position: absolute; clip: rect(3.179em 1000.67em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-160" style="font-family: MathJax_Math-italic;">L</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.669em;"><span class="mi" id="MathJax-Span-161" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-11">L_i</script> that this example contributes to the full objective. In other words, we want to derive the gradient <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-12-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2202;&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;/mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2202;&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-162" style="width: 4.46em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.64em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.283em 1003.64em 2.615em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-163"><span class="mi" id="MathJax-Span-164" style="font-family: MathJax_Main;">∂<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span class="msubsup" id="MathJax-Span-165"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px;"><span style="position: absolute; clip: rect(3.179em 1000.67em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-166" style="font-family: MathJax_Math-italic;">L</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.669em;"><span class="mi" id="MathJax-Span-167" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="texatom" id="MathJax-Span-168"><span class="mrow" id="MathJax-Span-169"><span class="mo" id="MathJax-Span-170" style="font-family: MathJax_Main;">/</span></span></span><span class="mi" id="MathJax-Span-171" style="font-family: MathJax_Main;">∂<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span class="msubsup" id="MathJax-Span-172"><span style="display: inline-block; position: relative; width: 0.925em; height: 0px;"><span style="position: absolute; clip: rect(3.128em 1000.57em 4.357em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-173" style="font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.515em;"><span class="mi" id="MathJax-Span-174" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.378em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">∂</mi><msub><mi>L</mi><mi>i</mi></msub><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mi mathvariant="normal">∂</mi><msub><mi>f</mi><mi>k</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-12"> \partial L_i / \partial f_k </script>. The loss <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-13-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-175" style="width: 1.283em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.386em 1001.03em 2.513em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-176"><span class="msubsup" id="MathJax-Span-177"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px;"><span style="position: absolute; clip: rect(3.179em 1000.67em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-178" style="font-family: MathJax_Math-italic;">L</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.669em;"><span class="mi" id="MathJax-Span-179" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-13">L_i</script> is computed from <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-14-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-180" style="width: 0.669em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.515em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.591em 1000.51em 2.564em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-181"><span class="mi" id="MathJax-Span-182" style="font-family: MathJax_Math-italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-14">p</script>, which in turn depends on <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-15-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-183" style="width: 0.72em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.566em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.335em 1000.57em 2.564em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-184"><span class="mi" id="MathJax-Span-185" style="font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></span></span><script type="math/tex" id="MathJax-Element-15">f</script>. It’s a fun exercise to the reader to use the chain rule to derive the gradient, but it turns out to be extremely simple and interpretible in the end, after a lot of things cancel out:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-16-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2202;&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x2202;&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn mathvariant=&quot;double-struck&quot;&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-186" style="width: 11.119em; display: inline-block;"><span style="display: inline-block; position: relative; width: 9.121em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(0.669em 1009.02em 3.23em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-187"><span class="mfrac" id="MathJax-Span-188"><span style="display: inline-block; position: relative; width: 1.693em; height: 0px; margin-right: 0.105em; margin-left: 0.105em;"><span style="position: absolute; clip: rect(3.128em 1001.59em 4.306em -999.997em); top: -4.659em; left: 50%; margin-left: -0.766em;"><span class="mrow" id="MathJax-Span-189"><span class="mi" id="MathJax-Span-190" style="font-family: MathJax_Main;">∂<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span class="msubsup" id="MathJax-Span-191"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px;"><span style="position: absolute; clip: rect(3.179em 1000.67em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-192" style="font-family: MathJax_Math-italic;">L</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.669em;"><span class="mi" id="MathJax-Span-193" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.128em 1001.49em 4.357em -999.997em); top: -3.327em; left: 50%; margin-left: -0.766em;"><span class="mrow" id="MathJax-Span-194"><span class="mi" id="MathJax-Span-195" style="font-family: MathJax_Main;">∂<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span class="msubsup" id="MathJax-Span-196"><span style="display: inline-block; position: relative; width: 0.925em; height: 0px;"><span style="position: absolute; clip: rect(3.128em 1000.57em 4.357em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-197" style="font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.515em;"><span class="mi" id="MathJax-Span-198" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(0.873em 1001.69em 1.232em -999.997em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.693em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.078em;"></span></span></span></span><span class="mo" id="MathJax-Span-199" style="font-family: MathJax_Main; padding-left: 0.259em;">=</span><span class="msubsup" id="MathJax-Span-200" style="padding-left: 0.259em;"><span style="display: inline-block; position: relative; width: 0.925em; height: 0px;"><span style="position: absolute; clip: rect(3.384em 1000.51em 4.357em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-201" style="font-family: MathJax_Math-italic;">p</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.515em;"><span class="mi" id="MathJax-Span-202" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="mo" id="MathJax-Span-203" style="font-family: MathJax_Main; padding-left: 0.207em;">−</span><span class="texatom" id="MathJax-Span-204" style="padding-left: 0.207em;"><span class="mrow" id="MathJax-Span-205"><span class="mn" id="MathJax-Span-206" style="font-family: MathJax_Main;">1</span></span></span><span class="mo" id="MathJax-Span-207" style="font-family: MathJax_Main;">(</span><span class="msubsup" id="MathJax-Span-208"><span style="display: inline-block; position: relative; width: 0.822em; height: 0px;"><span style="position: absolute; clip: rect(3.384em 1000.51em 4.357em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-209" style="font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.515em;"><span class="mi" id="MathJax-Span-210" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="mo" id="MathJax-Span-211" style="font-family: MathJax_Main; padding-left: 0.259em;">=</span><span class="mi" id="MathJax-Span-212" style="font-family: MathJax_Math-italic; padding-left: 0.259em;">k</span><span class="mo" id="MathJax-Span-213" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.122em; border-left: 0px solid; width: 0px; height: 2.941em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi>L</mi><mi>i</mi></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>f</mi><mi>k</mi></msub></mrow></mfrac><mo>=</mo><msub><mi>p</mi><mi>k</mi></msub><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mn mathvariant="double-struck">1</mn></mrow><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><mi>k</mi><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-16">\frac{\partial L_i }{ \partial f_k } = p_k - \mathbb{1}(y_i = k)</script>

<p>Notice how elegant and simple this expression is. Suppose the probabilities we computed were <code class="highlighter-rouge">p = [0.2, 0.3, 0.5]</code>, and that the correct class was the middle one (with probability 0.3). According to this derivation the gradient on the scores would be <code class="highlighter-rouge">df = [0.2, -0.7, 0.5]</code>. Recalling what the interpretation of the gradient, we see that this result is highly intuitive: increasing the first or last element of the score vector <code class="highlighter-rouge">f</code> (the scores of the incorrect classes) leads to an <em>increased</em> loss (due to the positive signs +0.2 and +0.5) - and increasing the loss is bad, as expected. However, increasing the score of the correct class has <em>negative</em> influence on the loss. The gradient of -0.7 is telling us that increasing the correct class score would lead to a decrease of the loss <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-17-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-214" style="width: 1.283em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.386em 1001.03em 2.513em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-215"><span class="msubsup" id="MathJax-Span-216"><span style="display: inline-block; position: relative; width: 1.027em; height: 0px;"><span style="position: absolute; clip: rect(3.179em 1000.67em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-217" style="font-family: MathJax_Math-italic;">L</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -3.84em; left: 0.669em;"><span class="mi" id="MathJax-Span-218" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-17">L_i</script>, which makes sense.</p>

<p>All of this boils down to the following code. Recall that <code class="highlighter-rouge">probs</code> stores the probabilities of all classes (as rows) for each example. To get the gradient on the scores, which we call <code class="highlighter-rouge">dscores</code>, we proceed as follows:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">dscores</span> <span class="o">=</span> <span class="n">probs</span>
<span class="n">dscores</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">),</span><span class="n">y</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
<span class="n">dscores</span> <span class="o">/=</span> <span class="n">num_examples</span>
</code></pre>
</div>

<p>Lastly, we had that <code class="highlighter-rouge">scores = np.dot(X, W) + b</code>, so armed with the gradient on <code class="highlighter-rouge">scores</code> (stored in <code class="highlighter-rouge">dscores</code>), we can now backpropagate into <code class="highlighter-rouge">W</code> and <code class="highlighter-rouge">b</code>:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dscores</span><span class="p">)</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dscores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">dW</span> <span class="o">+=</span> <span class="n">reg</span><span class="o">*</span><span class="n">W</span> <span class="c"># don't forget the regularization gradient</span>
</code></pre>
</div>

<p>Where we see that we have backpropped through the matrix multiply operation, and also added the contribution from the regularization. Note that the regularization gradient has the very simple form <code class="highlighter-rouge">reg*W</code> since we used the constant <code class="highlighter-rouge">0.5</code> for its loss contribution (i.e. <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-18-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mfrac&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;&amp;#x03BB;&lt;/mi&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-219" style="width: 8.404em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.867em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.13em 1006.82em 2.769em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-220"><span class="mfrac" id="MathJax-Span-221"><span style="display: inline-block; position: relative; width: 0.976em; height: 0px; margin-right: 0.105em; margin-left: 0.105em;"><span style="position: absolute; clip: rect(3.332em 1000.36em 4.152em -999.997em); top: -4.403em; left: 50%; margin-left: -0.202em;"><span class="mi" id="MathJax-Span-222" style="font-size: 70.7%; font-family: MathJax_Math-italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.332em 1000.87em 4.152em -999.997em); top: -3.584em; left: 50%; margin-left: -0.459em;"><span class="mrow" id="MathJax-Span-223"><span class="mi" id="MathJax-Span-224" style="font-size: 70.7%; font-family: MathJax_Math-italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-225" style="font-size: 70.7%; font-family: MathJax_Math-italic;">w</span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(0.873em 1000.98em 1.232em -999.997em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.976em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.078em;"></span></span></span></span><span class="mo" id="MathJax-Span-226" style="font-family: MathJax_Main;">(</span><span class="mfrac" id="MathJax-Span-227"><span style="display: inline-block; position: relative; width: 0.464em; height: 0px; margin-right: 0.105em; margin-left: 0.105em;"><span style="position: absolute; clip: rect(3.384em 1000.31em 4.152em -999.997em); top: -4.403em; left: 50%; margin-left: -0.151em;"><span class="mn" id="MathJax-Span-228" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.384em 1000.31em 4.152em -999.997em); top: -3.635em; left: 50%; margin-left: -0.151em;"><span class="mn" id="MathJax-Span-229" style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(0.873em 1000.46em 1.232em -999.997em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.464em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.078em;"></span></span></span></span><span class="mi" id="MathJax-Span-230" style="font-family: MathJax_Math-italic;">λ</span><span class="msubsup" id="MathJax-Span-231"><span style="display: inline-block; position: relative; width: 1.13em; height: 0px;"><span style="position: absolute; clip: rect(3.384em 1000.67em 4.152em -999.997em); top: -3.993em; left: 0em;"><span class="mi" id="MathJax-Span-232" style="font-family: MathJax_Math-italic;">w</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; top: -4.352em; left: 0.72em;"><span class="mn" id="MathJax-Span-233" style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="mo" id="MathJax-Span-234" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-235" style="font-family: MathJax_Main; padding-left: 0.259em;">=</span><span class="mi" id="MathJax-Span-236" style="font-family: MathJax_Math-italic; padding-left: 0.259em;">λ</span><span class="mi" id="MathJax-Span-237" style="font-family: MathJax_Math-italic;">w</span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.559em; border-left: 0px solid; width: 0px; height: 1.753em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mi>d</mi><mrow><mi>d</mi><mi>w</mi></mrow></mfrac><mo stretchy="false">(</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>λ</mi><msup><mi>w</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mi>λ</mi><mi>w</mi></math></span></span><script type="math/tex" id="MathJax-Element-18">\frac{d}{dw} ( \frac{1}{2} \lambda w^2) = \lambda w</script>. This is a common convenience trick that simplifies the gradient expression.</p>

<p><a name="update"></a></p>

<h3 id="performing-a-parameter-update">Performing a parameter update</h3>

<p>Now that we’ve evaluated the gradient we know how every parameter influences the loss function. We will now perform a parameter update in the <em>negative</em> gradient direction to <em>decrease</em> the loss:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># perform a parameter update</span>
<span class="n">W</span> <span class="o">+=</span> <span class="o">-</span><span class="n">step_size</span> <span class="o">*</span> <span class="n">dW</span>
<span class="n">b</span> <span class="o">+=</span> <span class="o">-</span><span class="n">step_size</span> <span class="o">*</span> <span class="n">db</span>
</code></pre>
</div>

<p><a name="together"></a></p>

<h3 id="putting-it-all-together-training-a-softmax-classifier">Putting it all together: Training a Softmax Classifier</h3>

<p>Putting all of this together, here is the full code for training a Softmax classifier with Gradient descent:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c">#Train a Linear Classifier</span>

<span class="c"># initialize parameters randomly</span>
<span class="n">W</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">D</span><span class="p">,</span><span class="n">K</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">K</span><span class="p">))</span>

<span class="c"># some hyperparameters</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="mf">1e-0</span>
<span class="n">reg</span> <span class="o">=</span> <span class="mf">1e-3</span> <span class="c"># regularization strength</span>

<span class="c"># gradient descent loop</span>
<span class="n">num_examples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
  
  <span class="c"># evaluate class scores, [N x K]</span>
  <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span> 
  
  <span class="c"># compute the class probabilities</span>
  <span class="n">exp_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
  <span class="n">probs</span> <span class="o">=</span> <span class="n">exp_scores</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">exp_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c"># [N x K]</span>
  
  <span class="c"># compute the loss: average cross-entropy loss and regularization</span>
  <span class="n">corect_logprobs</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">),</span><span class="n">y</span><span class="p">])</span>
  <span class="n">data_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">corect_logprobs</span><span class="p">)</span><span class="o">/</span><span class="n">num_examples</span>
  <span class="n">reg_loss</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">reg</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">W</span><span class="o">*</span><span class="n">W</span><span class="p">)</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">data_loss</span> <span class="o">+</span> <span class="n">reg_loss</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">"iteration </span><span class="si">%</span><span class="s">d: loss </span><span class="si">%</span><span class="s">f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
  
  <span class="c"># compute the gradient on scores</span>
  <span class="n">dscores</span> <span class="o">=</span> <span class="n">probs</span>
  <span class="n">dscores</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">),</span><span class="n">y</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
  <span class="n">dscores</span> <span class="o">/=</span> <span class="n">num_examples</span>
  
  <span class="c"># backpropate the gradient to the parameters (W,b)</span>
  <span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dscores</span><span class="p">)</span>
  <span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dscores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  
  <span class="n">dW</span> <span class="o">+=</span> <span class="n">reg</span><span class="o">*</span><span class="n">W</span> <span class="c"># regularization gradient</span>
  
  <span class="c"># perform a parameter update</span>
  <span class="n">W</span> <span class="o">+=</span> <span class="o">-</span><span class="n">step_size</span> <span class="o">*</span> <span class="n">dW</span>
  <span class="n">b</span> <span class="o">+=</span> <span class="o">-</span><span class="n">step_size</span> <span class="o">*</span> <span class="n">db</span>
</code></pre>
</div>

<p>Running this prints the output:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>iteration 0: loss 1.096956
iteration 10: loss 0.917265
iteration 20: loss 0.851503
iteration 30: loss 0.822336
iteration 40: loss 0.807586
iteration 50: loss 0.799448
iteration 60: loss 0.794681
iteration 70: loss 0.791764
iteration 80: loss 0.789920
iteration 90: loss 0.788726
iteration 100: loss 0.787938
iteration 110: loss 0.787409
iteration 120: loss 0.787049
iteration 130: loss 0.786803
iteration 140: loss 0.786633
iteration 150: loss 0.786514
iteration 160: loss 0.786431
iteration 170: loss 0.786373
iteration 180: loss 0.786331
iteration 190: loss 0.786302
</code></pre>
</div>

<p>We see that we’ve converged to something after about 190 iterations. We can evaluate the training set accuracy:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># evaluate training set accuracy</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
<span class="n">predicted_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span> <span class="s">'training accuracy: </span><span class="si">%.2</span><span class="s">f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted_class</span> <span class="o">==</span> <span class="n">y</span><span class="p">))</span>
</code></pre>
</div>

<p>This prints <strong>49%</strong>. Not very good at all, but also not surprising given that the dataset is constructed so it is not linearly separable. We can also plot the learned decision boundaries:</p>

<div class="fig figcenter fighighlight">
  <img src="./1-8-case-study_files/spiral_linear.png">
  <div class="figcaption">
    Linear classifier fails to learn the toy spiral dataset.
  </div>
</div>

<p><a name="net"></a></p>

<h2 id="training-a-neural-network">Training a Neural Network</h2>

<p>Clearly, a linear classifier is inadequate for this dataset and we would like to use a Neural Network. One additional hidden layer will suffice for this toy data. We will now need two sets of weights and biases (for the first and second layers):</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># initialize parameters randomly</span>
<span class="n">h</span> <span class="o">=</span> <span class="mi">100</span> <span class="c"># size of hidden layer</span>
<span class="n">W</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">D</span><span class="p">,</span><span class="n">h</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">h</span><span class="p">))</span>
<span class="n">W2</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">h</span><span class="p">,</span><span class="n">K</span><span class="p">)</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">K</span><span class="p">))</span>
</code></pre>
</div>

<p>The forward pass to compute scores now changes form:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># evaluate class scores with a 2-layer Neural Network</span>
<span class="n">hidden_layer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="c"># note, ReLU activation</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hidden_layer</span><span class="p">,</span> <span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
</code></pre>
</div>

<p>Notice that the only change from before is one extra line of code, where we first compute the hidden layer representation and then the scores based on this hidden layer. Crucially, we’ve also added a non-linearity, which in this case is simple ReLU that thresholds the activations on the hidden layer at zero.</p>

<p>Everything else remains the same. We compute the loss based on the scores exactly as before, and get the gradient for the scores <code class="highlighter-rouge">dscores</code> exactly as before. However, the way we backpropagate that gradient into the model parameters now changes form, of course. First lets backpropagate the second layer of the Neural Network. This looks identical to the code we had for the Softmax classifier, except we’re replacing <code class="highlighter-rouge">X</code> (the raw data), with the variable <code class="highlighter-rouge">hidden_layer</code>):</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># backpropate the gradient to the parameters</span>
<span class="c"># first backprop into parameters W2 and b2</span>
<span class="n">dW2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hidden_layer</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dscores</span><span class="p">)</span>
<span class="n">db2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dscores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre>
</div>

<p>However, unlike before we are not yet done, because <code class="highlighter-rouge">hidden_layer</code> is itself a function of other parameters and the data! We need to continue backpropagation through this variable. Its gradient can be computed as:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">dhidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dscores</span><span class="p">,</span> <span class="n">W2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</code></pre>
</div>

<p>Now we have the gradient on the outputs of the hidden layer. Next, we have to backpropagate the ReLU non-linearity. This turns out to be easy because ReLU during the backward pass is effectively a switch. Since <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-19-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-238" style="width: 7.277em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.945em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.283em 1005.84em 2.615em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-239"><span class="mi" id="MathJax-Span-240" style="font-family: MathJax_Math-italic;">r</span><span class="mo" id="MathJax-Span-241" style="font-family: MathJax_Main; padding-left: 0.259em;">=</span><span class="mi" id="MathJax-Span-242" style="font-family: MathJax_Math-italic; padding-left: 0.259em;">m</span><span class="mi" id="MathJax-Span-243" style="font-family: MathJax_Math-italic;">a</span><span class="mi" id="MathJax-Span-244" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-245" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-246" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-247" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-248" style="font-family: MathJax_Math-italic; padding-left: 0.156em;">x</span><span class="mo" id="MathJax-Span-249" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.378em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>r</mi><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-19">r = max(0, x)</script>, we have that <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-20-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-250" style="width: 7.226em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.894em; height: 0px; font-size: 122%;"><span style="position: absolute; clip: rect(1.13em 1005.79em 2.769em -999.997em); top: -2.2em; left: 0em;"><span class="mrow" id="MathJax-Span-251"><span class="mfrac" id="MathJax-Span-252"><span style="display: inline-block; position: relative; width: 0.873em; height: 0px; margin-right: 0.105em; margin-left: 0.105em;"><span style="position: absolute; clip: rect(3.332em 1000.67em 4.152em -999.997em); top: -4.403em; left: 50%; margin-left: -0.356em;"><span class="mrow" id="MathJax-Span-253"><span class="mi" id="MathJax-Span-254" style="font-size: 70.7%; font-family: MathJax_Math-italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-255" style="font-size: 70.7%; font-family: MathJax_Math-italic;">r</span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(3.332em 1000.72em 4.152em -999.997em); top: -3.584em; left: 50%; margin-left: -0.407em;"><span class="mrow" id="MathJax-Span-256"><span class="mi" id="MathJax-Span-257" style="font-size: 70.7%; font-family: MathJax_Math-italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-258" style="font-size: 70.7%; font-family: MathJax_Math-italic;">x</span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span><span style="position: absolute; clip: rect(0.873em 1000.87em 1.232em -999.997em); top: -1.278em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.873em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.078em;"></span></span></span></span><span class="mo" id="MathJax-Span-259" style="font-family: MathJax_Main; padding-left: 0.259em;">=</span><span class="mn" id="MathJax-Span-260" style="font-family: MathJax_Main; padding-left: 0.259em;">1</span><span class="mo" id="MathJax-Span-261" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-262" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-263" style="font-family: MathJax_Main; padding-left: 0.259em;">&gt;</span><span class="mn" id="MathJax-Span-264" style="font-family: MathJax_Main; padding-left: 0.259em;">0</span><span class="mo" id="MathJax-Span-265" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.205em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.559em; border-left: 0px solid; width: 0px; height: 1.753em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mi>d</mi><mi>r</mi></mrow><mrow><mi>d</mi><mi>x</mi></mrow></mfrac><mo>=</mo><mn>1</mn><mo stretchy="false">(</mo><mi>x</mi><mo>&gt;</mo><mn>0</mn><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-20">\frac{dr}{dx} = 1(x > 0) </script>. Combined with the chain rule, we see that the ReLU unit lets the gradient pass through unchanged if its input was greater than 0, but <em>kills it</em> if its input was less than zero during the forward pass. Hence, we can backpropagate the ReLU in place simply with:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># backprop the ReLU non-linearity</span>
<span class="n">dhidden</span><span class="p">[</span><span class="n">hidden_layer</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre>
</div>

<p>And now we finally continue to the first layer weights and biases:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># finally into W,b</span>
<span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dhidden</span><span class="p">)</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dhidden</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre>
</div>

<p>We’re done! We have the gradients <code class="highlighter-rouge">dW,db,dW2,db2</code> and can perform the parameter update. Everything else remains unchanged. The full code looks very similar:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># initialize parameters randomly</span>
<span class="n">h</span> <span class="o">=</span> <span class="mi">100</span> <span class="c"># size of hidden layer</span>
<span class="n">W</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">D</span><span class="p">,</span><span class="n">h</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">h</span><span class="p">))</span>
<span class="n">W2</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">h</span><span class="p">,</span><span class="n">K</span><span class="p">)</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">K</span><span class="p">))</span>

<span class="c"># some hyperparameters</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="mf">1e-0</span>
<span class="n">reg</span> <span class="o">=</span> <span class="mf">1e-3</span> <span class="c"># regularization strength</span>

<span class="c"># gradient descent loop</span>
<span class="n">num_examples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
  
  <span class="c"># evaluate class scores, [N x K]</span>
  <span class="n">hidden_layer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="c"># note, ReLU activation</span>
  <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hidden_layer</span><span class="p">,</span> <span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
  
  <span class="c"># compute the class probabilities</span>
  <span class="n">exp_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
  <span class="n">probs</span> <span class="o">=</span> <span class="n">exp_scores</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">exp_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c"># [N x K]</span>
  
  <span class="c"># compute the loss: average cross-entropy loss and regularization</span>
  <span class="n">corect_logprobs</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">),</span><span class="n">y</span><span class="p">])</span>
  <span class="n">data_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">corect_logprobs</span><span class="p">)</span><span class="o">/</span><span class="n">num_examples</span>
  <span class="n">reg_loss</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">reg</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">W</span><span class="o">*</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">reg</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">W2</span><span class="o">*</span><span class="n">W2</span><span class="p">)</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">data_loss</span> <span class="o">+</span> <span class="n">reg_loss</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">"iteration </span><span class="si">%</span><span class="s">d: loss </span><span class="si">%</span><span class="s">f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
  
  <span class="c"># compute the gradient on scores</span>
  <span class="n">dscores</span> <span class="o">=</span> <span class="n">probs</span>
  <span class="n">dscores</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">),</span><span class="n">y</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
  <span class="n">dscores</span> <span class="o">/=</span> <span class="n">num_examples</span>
  
  <span class="c"># backpropate the gradient to the parameters</span>
  <span class="c"># first backprop into parameters W2 and b2</span>
  <span class="n">dW2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hidden_layer</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dscores</span><span class="p">)</span>
  <span class="n">db2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dscores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="c"># next backprop into hidden layer</span>
  <span class="n">dhidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dscores</span><span class="p">,</span> <span class="n">W2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
  <span class="c"># backprop the ReLU non-linearity</span>
  <span class="n">dhidden</span><span class="p">[</span><span class="n">hidden_layer</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="c"># finally into W,b</span>
  <span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dhidden</span><span class="p">)</span>
  <span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dhidden</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  
  <span class="c"># add regularization gradient contribution</span>
  <span class="n">dW2</span> <span class="o">+=</span> <span class="n">reg</span> <span class="o">*</span> <span class="n">W2</span>
  <span class="n">dW</span> <span class="o">+=</span> <span class="n">reg</span> <span class="o">*</span> <span class="n">W</span>
  
  <span class="c"># perform a parameter update</span>
  <span class="n">W</span> <span class="o">+=</span> <span class="o">-</span><span class="n">step_size</span> <span class="o">*</span> <span class="n">dW</span>
  <span class="n">b</span> <span class="o">+=</span> <span class="o">-</span><span class="n">step_size</span> <span class="o">*</span> <span class="n">db</span>
  <span class="n">W2</span> <span class="o">+=</span> <span class="o">-</span><span class="n">step_size</span> <span class="o">*</span> <span class="n">dW2</span>
  <span class="n">b2</span> <span class="o">+=</span> <span class="o">-</span><span class="n">step_size</span> <span class="o">*</span> <span class="n">db2</span>
</code></pre>
</div>

<p>This prints:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>iteration 0: loss 1.098744
iteration 1000: loss 0.294946
iteration 2000: loss 0.259301
iteration 3000: loss 0.248310
iteration 4000: loss 0.246170
iteration 5000: loss 0.245649
iteration 6000: loss 0.245491
iteration 7000: loss 0.245400
iteration 8000: loss 0.245335
iteration 9000: loss 0.245292
</code></pre>
</div>

<p>The training accuracy is now:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># evaluate training set accuracy</span>
<span class="n">hidden_layer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hidden_layer</span><span class="p">,</span> <span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
<span class="n">predicted_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span> <span class="s">'training accuracy: </span><span class="si">%.2</span><span class="s">f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted_class</span> <span class="o">==</span> <span class="n">y</span><span class="p">))</span>
</code></pre>
</div>

<p>Which prints <strong>98%</strong>!. We can also visualize the decision boundaries:</p>

<div class="fig figcenter fighighlight">
  <img src="./1-8-case-study_files/spiral_net.png">
  <div class="figcaption">
    Neural Network classifier crushes the spiral dataset.
  </div>
</div>

<h2 id="summary">Summary</h2>

<p>We’ve worked with a toy 2D dataset and trained both a linear network and a 2-layer Neural Network. We saw that the change from a linear classifier to a Neural Network involves very few changes in the code. The score function changes its form (1 line of code difference), and the backpropagation changes its form (we have to perform one more round of backprop through the hidden layer to the first layer of the network).</p>

<ul>
  <li>You may want to look at this IPython Notebook code <a href="http://cs.stanford.edu/people/karpathy/cs231nfiles/minimal_net.html">rendered as HTML</a>.</li>
  <li>Or download the <a href="http://cs.stanford.edu/people/karpathy/cs231nfiles/minimal_net.ipynb">ipynb file</a></li>
</ul>


  </article>

</div>
      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">

    <div class="footer-col-1 column">
      <ul>
        
        <li>
          <a href="https://github.com/cs231n">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"></path>
              </svg>
            </span>
            <span class="username">cs231n</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/cs231n">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"></path>
              </svg>
            </span>
            <span class="username">cs231n</span>
          </a>
        </li>
        <li>
          <a href="mailto:karpathy@cs.stanford.edu">karpathy@cs.stanford.edu</a>
        </li>
      </ul>
    </div>

    <div class="footer-col-2 column">
        
    </div>

    <div class="footer-col-3 column">
      
    </div>

  </div>

</footer>


    <!-- mathjax -->
    <script type="text/javascript" src="./1-8-case-study_files/MathJax.js"></script>
    
<div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: MathJax_AMS, monospace;"></div></div></body><div id="cVim-status-bar" style="top: 0px;"></div><iframe src="./1-8-case-study_files/cmdline_frame.html" id="cVim-command-frame"></iframe></html>